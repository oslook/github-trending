[
  {
    "repo": "deepseek-ai/DeepSeek-Coder",
    "href": "https://github.com/deepseek-ai/DeepSeek-Coder",
    "about": "DeepSeek Coder: Let the Code Write Itself",
    "star": "19,276",
    "fork": "2,137",
    "timestamp": "2025-02-14T02:14:13.585341",
    "stars_today": "9,213 stars this month"
  },
  {
    "repo": "ollama/ollama",
    "href": "https://github.com/ollama/ollama",
    "about": "Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 2, and other large language models.",
    "star": "125,673",
    "fork": "10,157",
    "timestamp": "2025-02-14T02:14:13.585648",
    "stars_today": "18,614 stars this month"
  },
  {
    "repo": "open-webui/open-webui",
    "href": "https://github.com/open-webui/open-webui",
    "about": "User-friendly AI Interface (Supports Ollama, OpenAI API, ...)",
    "star": "73,572",
    "fork": "8,690",
    "timestamp": "2025-02-14T02:14:13.585935",
    "stars_today": "17,597 stars this month"
  },
  {
    "repo": "browser-use/browser-use",
    "href": "https://github.com/browser-use/browser-use",
    "about": "Make websites accessible for AI agents",
    "star": "28,125",
    "fork": "2,815",
    "timestamp": "2025-02-14T02:14:13.586232",
    "stars_today": "14,379 stars this month"
  },
  {
    "repo": "OpenBMB/MiniCPM-o",
    "href": "https://github.com/OpenBMB/MiniCPM-o",
    "about": "MiniCPM-o 2.6: A GPT-4o Level MLLM for Vision, Speech and Multimodal Live Streaming on Your Phone",
    "star": "18,377",
    "fork": "1,319",
    "timestamp": "2025-02-14T02:14:13.586516",
    "stars_today": "5,728 stars this month"
  },
  {
    "repo": "unslothai/unsloth",
    "href": "https://github.com/unslothai/unsloth",
    "about": "Finetune Llama 3.3, DeepSeek-R1 & Reasoning LLMs 2x faster with 70% less memory! ü¶•",
    "star": "28,866",
    "fork": "1,903",
    "timestamp": "2025-02-14T02:14:13.586831",
    "stars_today": "8,375 stars this month"
  },
  {
    "repo": "mlabonne/llm-course",
    "href": "https://github.com/mlabonne/llm-course",
    "about": "Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.",
    "star": "46,277",
    "fork": "4,916",
    "timestamp": "2025-02-14T02:14:13.587110",
    "stars_today": "5,241 stars this month"
  },
  {
    "repo": "ggerganov/llama.cpp",
    "href": "https://github.com/ggerganov/llama.cpp",
    "about": "LLM inference in C/C++",
    "star": "74,179",
    "fork": "10,701",
    "timestamp": "2025-02-14T02:14:13.587419",
    "stars_today": "3,829 stars this month"
  },
  {
    "repo": "Mintplex-Labs/anything-llm",
    "href": "https://github.com/Mintplex-Labs/anything-llm",
    "about": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, and more.",
    "star": "36,448",
    "fork": "3,525",
    "timestamp": "2025-02-14T02:14:13.587727",
    "stars_today": "6,285 stars this month"
  },
  {
    "repo": "Dokploy/dokploy",
    "href": "https://github.com/Dokploy/dokploy",
    "about": "Open Source Alternative to Vercel, Netlify and Heroku.",
    "star": "16,945",
    "fork": "867",
    "timestamp": "2025-02-14T02:14:13.588032",
    "stars_today": "6,139 stars this month"
  },
  {
    "repo": "assafelovic/gpt-researcher",
    "href": "https://github.com/assafelovic/gpt-researcher",
    "about": "LLM based autonomous agent that conducts deep local and web research on any topic and generates a long report with citations.",
    "star": "18,227",
    "fork": "2,372",
    "timestamp": "2025-02-14T02:14:13.588325",
    "stars_today": "2,554 stars this month"
  },
  {
    "repo": "Bin-Huang/chatbox",
    "href": "https://github.com/Bin-Huang/chatbox",
    "about": "User-friendly Desktop Client App for AI Models/LLMs (GPT, Claude, Gemini, Ollama...)",
    "star": "30,340",
    "fork": "2,889",
    "timestamp": "2025-02-14T02:14:13.588617",
    "stars_today": "5,701 stars this month"
  },
  {
    "repo": "exo-explore/exo",
    "href": "https://github.com/exo-explore/exo",
    "about": "Run your own AI cluster at home with everyday devices üì±üíª üñ•Ô∏è‚åö",
    "star": "22,689",
    "fork": "1,326",
    "timestamp": "2025-02-14T02:14:13.588899",
    "stars_today": "4,199 stars this month"
  },
  {
    "repo": "sgl-project/sglang",
    "href": "https://github.com/sgl-project/sglang",
    "about": "SGLang is a fast serving framework for large language models and vision language models.",
    "star": "9,482",
    "fork": "904",
    "timestamp": "2025-02-14T02:14:13.589193",
    "stars_today": "2,220 stars this month"
  },
  {
    "repo": "langgenius/dify",
    "href": "https://github.com/langgenius/dify",
    "about": "Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.",
    "star": "66,788",
    "fork": "9,759",
    "timestamp": "2025-02-14T02:14:13.589483",
    "stars_today": "8,559 stars this month"
  },
  {
    "repo": "mendableai/firecrawl",
    "href": "https://github.com/mendableai/firecrawl",
    "about": "üî• Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.",
    "star": "25,636",
    "fork": "2,083",
    "timestamp": "2025-02-14T02:14:13.589765",
    "stars_today": "4,119 stars this month"
  },
  {
    "repo": "infiniflow/ragflow",
    "href": "https://github.com/infiniflow/ragflow",
    "about": "RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.",
    "star": "35,628",
    "fork": "3,186",
    "timestamp": "2025-02-14T02:14:13.590045",
    "stars_today": "7,543 stars this month"
  },
  {
    "repo": "shadps4-emu/shadPS4",
    "href": "https://github.com/shadps4-emu/shadPS4",
    "about": "PlayStation 4 emulator for Windows, Linux and macOS written in C++",
    "star": "17,922",
    "fork": "1,101",
    "timestamp": "2025-02-14T02:14:13.590344",
    "stars_today": "4,952 stars this month"
  },
  {
    "repo": "vllm-project/vllm",
    "href": "https://github.com/vllm-project/vllm",
    "about": "A high-throughput and memory-efficient inference and serving engine for LLMs",
    "star": "37,677",
    "fork": "5,662",
    "timestamp": "2025-02-14T02:14:13.590657",
    "stars_today": "4,081 stars this month"
  }
]